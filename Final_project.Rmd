---
title: "Final Project"
author: "Kevin Ojo, Jon Rodriguez, Pablo Martinez Sepulveda, TJ Banks, Alex Johnson"
date: "4/22/2021"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Discussion of Business Problem 
>Our question of interest is: which factors cause a song to be more popular on Spotify? Additionally, what are the most and least important factors in predicting popularity?

>The answer to this question may have profound implications for music producers, executves, and artists. With the explosion of digital music distribution channels, a large number of musical artists have been able to flood the internet with music.  This has made it more difficult for artists to capture sustainable listener share and especially difficult for producers and record label executives to identify the "next big hit."  By predicting how listeners react to certain characteristics of a song; artists, producers, and label executives can prioritize their time and investment into music that would more likely appeal to listeners on Spotify.

>Our data uses a Spotify Dataset of Songs from 1921-2020 with over 160k tracks (link (Links to an external site.))


# Modeling of Popularity as a Continuous Outcome Variable

>In the data, "popularity" is a continuos variable on a scale of 1 to 100 measured for each song. The first part of our analysis will investigate popularity as a continuous variable, while the second part will attempt to predict popularity as a dichotomous variable.

## Setting up for Linear Regression
```{r}
sdata <- read.csv("data.csv")

str(sdata)
summary(sdata)

sdata$explicit <- as.factor(sdata$explicit)
sdata$mode <- as.factor(sdata$mode)
sdata$decade <- as.factor(trunc(sdata$year / 10) *10)

hist(sdata$popularity)
```
>After importing the data and changing categorical variables to factors - including changing the original year variable into a categorical variable for decade - we look into the broad shape of our data. The histogram shows that popularity for songs is highly skewed with many songs not popular and few songs reaching the upper end of the distribution.

## Linear Regression
```{r}
model1 <- lm(popularity ~ acousticness + danceability + duration_ms + energy 
             + explicit + instrumentalness + key + liveness + loudness 
             + speechiness + tempo + tempo + valence +mode + decade, 
             data = sdata )

summary(model1)
```
>We optimized our linear regression by iterating across models removing variables that were not statistically significant and including the newly created 'decade' factor. Even with the number of variables in the linear regression, our model predicts ~50% of the variation in popularity (Adjusted R-squared: 0.5071). This model has the added benefit of being very explanable. For example, we can see that 'instrumentalness' is statistically significant at the .001 level and has the largest maganitude of any factor (negative relationship with popularity).

### Assessing Regression

```{r}
set.seed(12345)
testset = sample(1:nrow(sdata), 0.2*nrow(sdata))
sdata_test = sdata[testset, ]
sdata_train = sdata[-testset, ]
```

## Linear Regression Using Train / Test Split

```{r}
model1_train <- lm(popularity ~ acousticness + danceability + duration_ms + energy 
             + explicit + instrumentalness + key + liveness + loudness 
             + speechiness + tempo + tempo + valence +mode + decade, 
             data = sdata_train )

summary(model1_train)
```

```{r}
popular_predict = predict(model1_train, sdata_test)

cor(popular_predict, sdata_test$popularity)
```

>As shown above, when assessing the linear regression model on training and test data - the model performs well with .72 correlation between predicted popularity and actual popularity in the test data

## ANN Model

>To prep the data for ANN, we first removed the variables that are unneccesary such as the track ID and song name. To avoid our model from being skewed by the scale of variables we normalized the data after converting all variables into numeric data using model matrix.

```{r}
library(neuralnet)
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

spotify_draft = sdata
str(spotify_draft)
spotify_draft$artists = NULL
spotify_draft$id = NULL
spotify_draft$name = NULL
spotify_draft$release_date = NULL
spotify_draft$year = NULL

str(spotify_draft)

spotify_mmatrix <- as.data.frame(model.matrix(~. - 1,spotify_draft))
  

spotify_norm <- as.data.frame(lapply(spotify_mmatrix, normalize))

set.seed(12345)
testset = sample(1:nrow(spotify_norm), 0.2*nrow(spotify_norm))
spotify_norm_test = spotify_norm[testset, ]
spotify_norm_train = spotify_norm[-testset, ]

str(spotify_norm_train)

ann_model <- neuralnet(formula = popularity ~ ., data = spotify_norm_train[1:17000, ])
plot(ann_model)

# obtain model results
model_results <- compute(ann_model, spotify_norm_test[1:17000, ])
# obtain predicted strength values
predicted_pop <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_pop, spotify_norm_test$popularity[1:17000])
```

>Running the ANN on a subset of the randomized test and train data, we can see that our ANN prediction results have a correlation coefficient of .69 when compared to the test data. This correlation is slighly less than our results from the linear regression. 

# Modeling of Popularity as a Categorical Outcome Variable

## Logistic Regression (Kevin)

#### Data Cleaning and Manipulation
```{r}
sdata_test$popularity2 = as.factor(ifelse(sdata_test$popularity>42,1,0))
sdata_train$popularity2 = as.factor(ifelse(sdata_train$popularity>42,1,0))

plot(sdata_train$popularity2)

log_model1= glm(popularity2 ~  acousticness + danceability + duration_ms + energy + explicit + instrumentalness + key + liveness + loudness + speechiness + tempo + valence +decade ,data = sdata_train, family = "binomial")

summary(log_model1)

```

#### Predicting and classification logistic regression

```{r}

log1_predict = predict(log_model1, sdata_test)
log1_predict = ifelse(log1_predict > 0.1, 1, 0)
log1_predict = as.factor(log1_predict)

library(caret)

confusionMatrix(log1_predict, sdata_test$popularity2)

```

## KNN

```{r}

library(class)

spotify_norm_train$popularity = as.factor(ifelse(spotify_norm_train$popularity>.42,1,0))
spotify_norm_test$popularity = as.factor(ifelse(spotify_norm_test$popularity>.42,1,0))

spotify_norm_train_x = spotify_norm_train[,-12]
spotify_norm_train_y = spotify_norm_train[,12]

spotify_norm_test_x = spotify_norm_test[,-12]
spotify_norm_test_y = spotify_norm_test[,12]


#K determined based on square root of the number of observations in the train set 
KNN_model <- knn(train = spotify_norm_train_x, test = spotify_norm_test_x,
                      cl = spotify_norm_train_y, k= round(sqrt(nrow(spotify_norm_train_x))))

library(gmodels)
#Confusion matrix
CrossTable(x = spotify_norm_test_y, y = KNN_model, 
           prop.chisq=FALSE)

library(caret)

confusionMatrix(spotify_norm_test_y, KNN_model)

```

>For our KNN model, we started by separating our independent x variables from our dependent y outcomes (also called labels). We also converted our outcome of interest (y variable) popularity into a dictomous factor using a cut off of .42 to determine a "1" for a popular song. We used .42 in line with our logistic model because upon investigating the data a popularity score of 42 represented the third quartile of data. We created test and train data sets and used a k value of 374 neighbors based on the squareroot of the number of rows in the train data set. Our KNN model has a Kappa Statistic of .4781.

## Conclusion and Discussion of Results 

<Insert overall conclusion>

# TO DELETE????

## Linear Regression: Optimizing Performance

```{r}
model2 <- lm( popularity ~ acousticness + danceability + energy + explicit + instrumentalness + key + liveness + speechiness + valence +mode,data = sdata )

summary(model2)
```



















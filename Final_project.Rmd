---
title: "Final Project"
author: "Kevin Ojo, Jon Rodriguez, Pablo Martinez Sepulveda, TJ Banks, Alex Johnson"
date: "4/22/2021"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Discussion of Business Problem 
>Our question of interest is: which factors cause a song to be more popular on Spotify? Additionally, what are the most and least important factors in predicting popularity?

>The answer to this question may have profound implications for music producers, executves, and artists. With the explosion of digital music distribution channels, a large number of musical artists have been able to flood the internet with music.  This has made it more difficult for artists to capture sustainable listener share and especially difficult for producers and record label executives to identify the "next big hit."  By predicting how listeners react to certain characteristics of a song; artists, producers, and label executives can prioritize their time and investment into music that would more likely appeal to listeners on Spotify.

>Our data uses a Spotify Dataset of Songs from 1921-2020 with over 160k tracks (link (Links to an external site.))


# Modeling of Popularity as a Continuous Outcome Variable

>In the data, "popularity" is a continuos variable on a scale of 1 to 100 measured for each song. The first part of our analysis will investigate popularity as a continuous variable, while the second part will attempt to predict popularity as a dichotomous variable.

## Setting up for Linear Regression
```{r}
sdata <- read.csv("data.csv")

str(sdata)
summary(sdata)

sdata$explicit <- as.factor(sdata$explicit)
sdata$mode <- as.factor(sdata$mode)
sdata$decade <- as.factor(trunc(sdata$year / 10) *10)

hist(sdata$popularity)
```
>After importing the data and changing categorical variables to factors - including changing the original year variable into a categorical variable for decade - we look into the broad shape of our data. The histogram shows that popularity for songs is highly skewed with many songs not popular and few songs reaching the upper end of the distribution.

## Linear Regression
```{r}
model1 <- lm(popularity ~ acousticness + danceability + duration_ms + energy 
             + explicit + instrumentalness + key + liveness + loudness 
             + speechiness + tempo + tempo + valence +mode + decade, 
             data = sdata )

summary(model1)
```
>We optimized our linear regression by iterating across models removing variables that were not statistically significant and including the newly created 'decade' factor. Even with the number of variables in the linear regression, our model predicts ~50% of the variation in popularity (Adjusted R-squared: 0.5071). This model has the added benefit of being very explanable. For example, we can see that 'instrumentalness' is statistically significant at the .001 level and has the largest maganitude of any factor (negative relationship with popularity).

### Assessing Regression

```{r}
set.seed(12345)
testset = sample(1:nrow(sdata), 0.2*nrow(sdata))
sdata_test = sdata[testset, ]
sdata_train = sdata[-testset, ]
```

## Linear Regression Using Train / Test Split

```{r}
model1_train <- lm(popularity ~ acousticness + danceability + duration_ms + energy 
             + explicit + instrumentalness + key + liveness + loudness 
             + speechiness + tempo + tempo + valence +mode + decade, 
             data = sdata_train )

summary(model1_train)
```

```{r}
popular_predict = predict(model1_train, sdata_test)

cor(popular_predict, sdata_test$popularity)
```

>As shown above, when assessing the linear regression model on training and test data - the model performs well with .72 correlation between predicted popularity and actual popularity in the test data

## ANN Model

>To prep the data for ANN, we first removed the variables that are unneccesary such as the track ID and song name. To avoid our model from being skewed by the scale of variables we normalized the data after converting all variables into numeric data using model matrix.  Given the high number of observations, we also chose to run the ANN on a randomized subset of the original dataset to reduce runtime. 

```{r}
library(neuralnet)
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

spotify_draft = sdata
str(spotify_draft)
spotify_draft$artists = NULL
spotify_draft$id = NULL
spotify_draft$name = NULL
spotify_draft$release_date = NULL
spotify_draft$year = NULL

str(spotify_draft)

spotify_mmatrix <- as.data.frame(model.matrix(~. - 1,spotify_draft))
  

spotify_norm <- as.data.frame(lapply(spotify_mmatrix, normalize))

set.seed(12345)
testset = sample(1:nrow(spotify_norm), 0.2*nrow(spotify_norm))
spotify_norm_test = spotify_norm[testset, ]
spotify_norm_train = spotify_norm[-testset, ]

str(spotify_norm_train)

ann_model <- neuralnet(formula = popularity ~ ., data = spotify_norm_train[1:17000, ])
plot(ann_model)

# obtain model results
model_results <- compute(ann_model, spotify_norm_test[1:17000, ])
# obtain predicted strength values
predicted_pop <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_pop, spotify_norm_test$popularity[1:17000])
```

>Running the ANN on a subset of the randomized test and train data, we can see that our ANN prediction results have a correlation coefficient of .69 when compared to the test data. This correlation is slighly less than our results from the linear regression. 

# Modeling of Popularity as a Categorical Outcome Variable

## Logistic Regression 
>In the original dataset, popularity is a continuous variable from 0-100.  However, we also wanted to assess popularity in a binary, categorical sense: is the song popular, or is it not?  To do so, we created a new factor outcome variable, popularity2, which is a 1 if popularity is greater than 42 and is 0 if popularity is less than 42. 42 was selected as the cutoff since it is the third quartile of popularity. 

#### Data Cleaning and Manipulation
```{r}
sdata_test$popularity2 = as.factor(ifelse(sdata_test$popularity>42,1,0))
sdata_train$popularity2 = as.factor(ifelse(sdata_train$popularity>42,1,0))

plot(sdata_train$popularity2)

log_model1= glm(popularity2 ~  acousticness + danceability + duration_ms + energy + explicit + instrumentalness + key + liveness + loudness + speechiness + tempo + valence +decade ,data = sdata_train, family = "binomial")

summary(log_model1)

```

#### Predicting and classification logistic regression

```{r}

log1_predict = predict(log_model1, sdata_test)
log1_predict = ifelse(log1_predict > 0.1, 1, 0)
log1_predict = as.factor(log1_predict)

library(caret)

confusionMatrix(log1_predict, sdata_test$popularity2)

```

>The logistic regrssion for prediciting "popular" or "not popular" results in a Kappa statistic of 0.4449 and overindexes on false positives, with fewer fals negatives. This is better for our business case of predicting hit songs, given that investment in a single song is minimal but the financial result of a hit song can be very large. 

## KNN
>For our KNN model, we started by separating our independent x variables from our dependent y outcomes (also called labels). We also converted our outcome of interest (y variable) popularity into a dichotomous factor using a cut off of .42 to determine a "1" for a popular song. We used .42 in line with our logistic model because upon investigating the data a popularity score of 42 represented the third quartile of data. We created test and train data sets and used a k value of 374 neighbors based on the squareroot of the number of rows in the train data set. 

>Like our ANN analysis, we ran KNN on a randomized subset of the original dataset due to the dataset's size and associated runtime.  

```{r}

library(class)

spotify_norm_train$popularity = as.factor(ifelse(spotify_norm_train$popularity>.42,1,0))
spotify_norm_test$popularity = as.factor(ifelse(spotify_norm_test$popularity>.42,1,0))

spotify_norm_train_x = spotify_norm_train[,-12]
spotify_norm_train_y = spotify_norm_train[,12]

spotify_norm_test_x = spotify_norm_test[,-12]
spotify_norm_test_y = spotify_norm_test[,12]


#K determined based on square root of the number of observations in the train set 
KNN_model <- knn(train = spotify_norm_train_x[1:17000,], test = spotify_norm_test_x[1:17000,],
                      cl = spotify_norm_train_y[1:17000], k= round(sqrt(nrow(spotify_norm_train_x[1:17000,]))))

library(gmodels)
#Confusion matrix
CrossTable(x = spotify_norm_test_y[1:17000], y = KNN_model, 
           prop.chisq=FALSE)

library(caret)

confusionMatrix(spotify_norm_test_y[1:17000], KNN_model)

```

>Our KNN model has a Kappa Statistic of .2615, indicating worse overall performance than the logistic regression.  However, the KNN model results in far fewer false negatives, indicating we may be able to predict more hit songs.  If the investment in songs is minimal and the payout in hits is significant, this may be a better method for prediction. 

## Conclusion and Discussion of Results 

>In both cases of analyzing song popularity - either a continuous or categorical output variable - the simpler model performs better when analyzing results.  

>The linear regression model produces a slightly higher correlation between train / test outcomes (0.72) versus the ANN model (0.69). This result, combined with the the fact that the linear regression is not a black box, leads us to conclude the linear regression may be a better model for our purposes.  Based on the results of the linear regression, it can be determined that there are a few important factors to predict song popularity: dancability and whether the song is from the 1950s are top predictors for popularity, while energy, instrumentallness, and liveness are top predictors for being less popular.  These results somewhat surprised us, particularly the association of popularity with the 1950s.  Our hypothesis of the reason for this finding is that only songs that were already excessively popular performed by popular artists from the 1950s are on Spotify, while there is a plethora of modern songs on Spotify, many of which will not be popular and may be of middling quality.  The linear regression was both highly significant and explained a large proportion of the variance of outcome, with an R-squared of 0.5.  However, much of the variation can be explained by decade, so additional analysis might need to be done to strip away impact of decade when determining whether to invest in a modern-day song.

>When analyzing popularity as a binary categorical variable, we introduced two levels of subjectivity that in future use would need to be constantly justified: the cutoff of what constitues "popular" (in our case, we decided on a level 42 popularity which is the third quartile) and the prediction odds threshold that would consititute popularity when predicting results for logistic regression (we chose 0.1 given the skewness of the data). While the logistic regression with these parameters performed better than the KNN, the KNN was subject to only one of these subjective parameters, which may lend itself to a more objective estimation. In that vein, KNN also had much fewer false negatives, which may impact potential financial return of hit songs are missed. 
















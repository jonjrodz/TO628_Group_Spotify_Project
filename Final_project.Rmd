---
title: "Final Project"
author: "Kevin Ojo, Jon Rodriguez, Pablo Martinez Sepulveda, TJ Banks, Alex Johnson"
date: "4/22/2021"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and Discussion of Business Problem 
Our is asking the question: which factors cause a song or artist to be more popular on Spotify?  What are the most important and least important factors in predicting popularity?

The answer to this question may have profound implications for music producers, executves, and artists. With the explosion of digital music distribution channels, a huge number of musical artists have been able to flood the internet with their music.  This has made it more difficult for artists to capture sustainable listener share and especially difficult for producers and record label executives to identify the "next big thing" before it happens.  By predicting how listeners react to certain characteristics of a song or album, artists, producers, and label executives can prioritize their time and investment into music that would more likely appeal to listeners on Spotify.

Dataset: Spotify Dataset of Songs from 1921-2020, 160k+ Tracks (link (Links to an external site.))


# Modeling of Popularity as a Continuous Outcome Variable (Jon / Pablo)
Popularity is assessed on a 1-100 scale for each song.  We began our analysis predicting popularity on the same continuous scale.

## Linear Regression
```{r}
##Importing Data

sdata <- read.csv("data.csv")

str(sdata)
summary(sdata)

sdata$explicit <- as.factor(sdata$explicit)
sdata$mode <- as.factor(sdata$mode)
sdata$decade <- as.factor(trunc(sdata$year / 10) *10)

hist(sdata$popularity)

```

## Linear Regression
```{r}

model1 <- lm( popularity ~ acousticness + danceability + duration_ms + energy + explicit + instrumentalness + key + liveness + loudness + speechiness + tempo + tempo + valence +mode +
                decade,data = sdata )

summary(model1)

```
## Linear Regression: Optimizing Performance
```{r}
model2 <- lm( popularity ~ acousticness + danceability + energy + explicit + instrumentalness + key + liveness + speechiness + valence +mode,data = sdata )

summary(model2)

```

### Assessing Regression

```{r}

set.seed(12345)
testset = sample(1:nrow(sdata), 0.2*nrow(sdata))
sdata_test = sdata[testset, ]
sdata_train = sdata[-testset, ]

```

## Linear Regression Using Train / Test Split

```{r}
model3 <- lm( popularity ~ acousticness + danceability + duration_ms + energy + explicit + instrumentalness + key + liveness + speechiness + valence ,data = sdata_train )

summary(model3)


```

```{r}

popular_predict = predict(model3, sdata_test)

cor(popular_predict, sdata_test$popularity)


```

## ANN Model

```{r}
library(neuralnet)



normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}

spotify_draft = sdata
str(spotify_draft)
spotify_draft$artists = NULL
spotify_draft$id = NULL
spotify_draft$name = NULL
spotify_draft$release_date = NULL
spotify_draft$year = NULL

str(spotify_draft)

spotify_mmatrix <- as.data.frame(model.matrix(~. - 1,spotify_draft))
  

spotify_norm <- as.data.frame(lapply(spotify_mmatrix, normalize))

set.seed(12345)
testset = sample(1:nrow(spotify_norm), 0.2*nrow(spotify_norm))
spotify_norm_test = spotify_norm[testset, ]
spotify_norm_train = spotify_norm[-testset, ]

str(spotify_norm_train)

ann_model <- neuralnet(formula = popularity ~ ., data = spotify_norm_train)
plot(ann_model)

# obtain model results
model_results <- compute(ann_model, spotify_norm_test)
# obtain predicted strength values
predicted_pop <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_pop, spotify_norm_test$popularity)


```
# Modeling of Popularity as a Categorical Outcome Variable

## Logistic Regression (Kevin)

#### Data Cleaning and Manipulation
```{r}
sdata_test$popularity2 = as.factor(ifelse(sdata_test$popularity>42,1,0))
sdata_train$popularity2 = as.factor(ifelse(sdata_train$popularity>42,1,0))

plot(sdata_train$popularity2)

log_model1= glm(popularity2 ~  acousticness + danceability + duration_ms + energy + explicit + instrumentalness + key + liveness + loudness + speechiness + tempo + valence +decade ,data = sdata_train, family = "binomial")

summary(log_model1)

```

#### Predicting and classification logistic regression

```{r}

log1_predict = predict(log_model1, sdata_test)
log1_predict = ifelse(log1_predict > 0.1, 1, 0)
log1_predict = as.factor(log1_predict)

library(caret)

confusionMatrix(log1_predict, sdata_test$popularity2)

```

## KNN (TJ)

```{r}

library(class)

spotify_norm_train$popularity = as.factor(ifelse(spotify_norm_train$popularity>.42,1,0))
spotify_norm_test$popularity = as.factor(ifelse(spotify_norm_test$popularity>.42,1,0))

spotify_norm_train_x = spotify_norm_train[,-12]
spotify_norm_train_y = spotify_norm_train[,12]

spotify_norm_test_x = spotify_norm_test[,-12]
spotify_norm_test_y = spotify_norm_test[,12]


#K determined based on square root of the number of observations in the train set 
KNN_model <- knn(train = spotify_norm_train_x, test = spotify_norm_test_x,
                      cl = spotify_norm_train_y, k= round(sqrt(nrow(spotify_norm_train_x))))

library(gmodels)
#Confusion matrix
CrossTable(x = spotify_norm_test_y, y = KNN_model, 
           prop.chisq=FALSE)

library(caret)

confusionMatrix(spotify_norm_test_y, KNN_model)

```

## Conclusion and Discussion of Results 

<Insert overall conclusion>




















